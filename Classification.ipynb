{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":77497,"databundleVersionId":8485162,"sourceType":"competition"}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n\ndef dataframelabeling(training_dir, testing_dir):\n    train_fnames = []\n    train_labels = []\n\n    for root, _, files in os.walk(training_dir):\n        for f in files:\n            ext = os.path.splitext(f)[1].lower()\n            if ext in \".jpg\":\n                fname = os.path.join(root, f)\n                label, _ = f.split(\"_\", 1)\n                train_fnames.append(fname)\n                train_labels.append(label)\n\n    trainingdf = pd.DataFrame({\n        \"Filename\": train_fnames,\n        \"Label\": train_labels,\n    })\n\n    test_fnames = []\n    test_labels = []\n\n    for root, _, files in os.walk(testing_dir):\n        for f in files:\n            ext = os.path.splitext(f)[1].lower()\n            if ext in \".jpg\":\n                fname = os.path.join(root, f)\n                label = \"_\".join(f.split(\"_\")[:-1])\n                test_fnames.append(fname)\n                test_labels.append(label)\n\n    testingdf = pd.DataFrame({\n        \"Filename\": test_fnames,\n        \"Label\": test_labels,\n    })\n    \n    return trainingdf, testingdf\n\ndef imagemaker(training_dir, testing_dir):\n    trainingdf, testingdf = dataframelabeling(training_dir, testing_dir)\n    \n    train_set = ImageDataGenerator(\n        rescale = 1.0 / 255,\n        validation_split = 0.2\n    ).flow_from_dataframe(\n        dataframe=trainingdf,\n        directory=training_dir,\n        x_col=\"Filename\",\n        y_col=\"Label\",\n        target_size=(64, 64),\n        batch_size=64,\n        class_mode=\"categorical\",\n        shuffle=True,\n        subset=\"training\",\n        color_mode=\"grayscale\"\n    )\n\n    validation_set = ImageDataGenerator(\n        rescale = 1.0 / 255,\n        validation_split = 0.8\n    ).flow_from_dataframe(\n        dataframe=trainingdf,\n        directory=training_dir,\n        x_col=\"Filename\",\n        y_col=\"Label\",\n        target_size=(64, 64),\n        batch_size=64,\n        class_mode=\"categorical\",\n        shuffle=True,\n        subset=\"validation\",\n        color_mode=\"grayscale\"\n    )\n\n    test_set = ImageDataGenerator(\n        rescale = 1.0 / 255\n    ).flow_from_dataframe(\n        dataframe=testingdf,\n        directory=testing_dir,\n        x_col=\"Filename\",\n        y_col=None,\n        target_size=(64, 64),\n        batch_size=64,\n        class_mode=None,\n        color_mode=\"grayscale\"\n    )\n\n    return train_set, validation_set, test_set\n\ndef buildmodel():\n    model = tf.keras.models.Sequential()\n    model.add(tf.keras.layers.Conv2D(64,(3,3),activation=\"relu\",input_shape=(64,64,1)))\n    model.add(tf.keras.layers.MaxPooling2D(2,2))\n    model.add(tf.keras.layers.Conv2D(128,(3,3),activation=\"relu\"))\n    model.add(tf.keras.layers.MaxPooling2D(2,2))\n    model.add(tf.keras.layers.Flatten())\n    model.add(tf.keras.layers.Dense(512,activation=\"relu\"))\n    model.add(tf.keras.layers.Dense(256,activation=\"relu\"))\n    model.add(tf.keras.layers.Dense(30,activation=\"softmax\"))\n\n    model.compile(\n        optimizer=\"adam\",\n        loss=\"categorical_crossentropy\",\n        metrics=[\"accuracy\"]\n    )\n\n    return model\n\ndef trainmodel(model, train_set, validation_set):\n    HangulClassificator = model.fit(\n        train_set,\n        validation_data=validation_set,\n        epochs=15\n    )\n\ndef predictmodel(model, train_set, test_set):\n    labels = train_set.class_indices\n    labels = dict((a, l) for l, a in labels.items())\n\n    predictions = model.predict(test_set, steps=len(test_set), verbose=1)\n\n    submission_data = []\n    for i, pred in enumerate(predictions):\n        image_id = test_set.filenames[i].split(\".\")[0]\n        answer = labels[np.argmax(pred)]\n        submission_data.append([image_id, answer])\n\n    submission_df = pd.DataFrame(submission_data, columns=[\"ID\", \"ANSWER\"])\n    \n    submission_df['ID'] = submission_df['ID'].str.extract('(\\d+)').astype(int)\n    submission_df = submission_df.sort_values(by='ID')\n    submission_df['ID'] = 'test' + submission_df['ID'].astype(str)\n\n    submission_df.to_csv(\"HangulClassification.csv\", index=False)\n\ntraining_dir = \"/kaggle/input/uts-praktikum-artificial-intelligence/hangul_dataset/hangul_characters_v1\"\ntesting_dir = \"/kaggle/input/uts-praktikum-artificial-intelligence/testing/testing\"\n\ntrain_set, validation_set, test_set = imagemaker(training_dir, testing_dir)\n\nmodel = buildmodel()\n\ntrainmodel(model, train_set, validation_set)    \n    \npredictmodel(model, train_set, test_set)\n    \nmodel.save(\"model.h5\")","metadata":{"execution":{"iopub.status.busy":"2025-06-22T14:57:07.573985Z","iopub.execute_input":"2025-06-22T14:57:07.574452Z","iopub.status.idle":"2025-06-22T15:04:32.309241Z","shell.execute_reply.started":"2025-06-22T14:57:07.574410Z","shell.execute_reply":"2025-06-22T15:04:32.307973Z"},"trusted":true},"outputs":[{"name":"stderr","text":"2025-06-22 14:57:12.631468: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-06-22 14:57:12.631635: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-06-22 14:57:12.837236: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Found 1920 validated image filenames belonging to 30 classes.\nFound 1920 validated image filenames belonging to 30 classes.\nFound 30 validated image filenames.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/15\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 850ms/step - accuracy: 0.1494 - loss: 3.1620 - val_accuracy: 0.7094 - val_loss: 1.0392\nEpoch 2/15\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 824ms/step - accuracy: 0.7711 - loss: 0.8077 - val_accuracy: 0.8750 - val_loss: 0.4093\nEpoch 3/15\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 772ms/step - accuracy: 0.9155 - loss: 0.2813 - val_accuracy: 0.9099 - val_loss: 0.3105\nEpoch 4/15\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 802ms/step - accuracy: 0.9520 - loss: 0.1823 - val_accuracy: 0.9484 - val_loss: 0.1798\nEpoch 5/15\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 766ms/step - accuracy: 0.9784 - loss: 0.0796 - val_accuracy: 0.9792 - val_loss: 0.0904\nEpoch 6/15\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 774ms/step - accuracy: 0.9942 - loss: 0.0238 - val_accuracy: 0.9781 - val_loss: 0.0881\nEpoch 7/15\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 784ms/step - accuracy: 0.9967 - loss: 0.0130 - val_accuracy: 0.9786 - val_loss: 0.0933\nEpoch 8/15\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 782ms/step - accuracy: 0.9929 - loss: 0.0251 - val_accuracy: 0.9609 - val_loss: 0.1470\nEpoch 9/15\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 826ms/step - accuracy: 0.9836 - loss: 0.0494 - val_accuracy: 0.9818 - val_loss: 0.0781\nEpoch 10/15\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 743ms/step - accuracy: 0.9966 - loss: 0.0119 - val_accuracy: 0.9859 - val_loss: 0.0755\nEpoch 11/15\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 736ms/step - accuracy: 0.9971 - loss: 0.0075 - val_accuracy: 0.9828 - val_loss: 0.0813\nEpoch 12/15\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 720ms/step - accuracy: 0.9985 - loss: 0.0052 - val_accuracy: 0.9870 - val_loss: 0.0698\nEpoch 13/15\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 750ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9865 - val_loss: 0.0738\nEpoch 14/15\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 943ms/step - accuracy: 1.0000 - loss: 7.1689e-04 - val_accuracy: 0.9875 - val_loss: 0.0722\nEpoch 15/15\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 822ms/step - accuracy: 1.0000 - loss: 3.3358e-04 - val_accuracy: 0.9865 - val_loss: 0.0723\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step\n","output_type":"stream"}],"execution_count":1}]}